apiVersion: camel.apache.org/v1
kind: Integration
metadata:
  name: iot-kafka2s3-integration
spec:
  configuration:
    - type: configmap
      value: iot-kafka2s3-config
    - type: secret
      value: iot-kafka2s3-secret  
  profile: OpenShift
  sources:
    - content: "package com.redhat.manuela.routes;\n\nimport java.io.ByteArrayInputStream;\nimport java.util.Iterator;\nimport java.util.List;\n\nimport org.apache.camel.Exchange;\nimport org.apache.camel.Processor;\nimport org.apache.camel.PropertyInject;\nimport org.apache.camel.builder.RouteBuilder;\nimport org.apache.camel.component.aws.s3.S3Constants;\nimport org.apache.camel.model.OnCompletionDefinition;\nimport org.apache.camel.processor.aggregate.GroupedBodyAggregationStrategy;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport com.amazonaws.ClientConfiguration;\nimport com.amazonaws.Protocol;\nimport com.amazonaws.SDKGlobalConfiguration;\nimport com.amazonaws.auth.AWSStaticCredentialsProvider;\nimport com.amazonaws.auth.BasicAWSCredentials;\nimport com.amazonaws.client.builder.AwsClientBuilder.EndpointConfiguration;\nimport com.amazonaws.services.s3.AmazonS3;\nimport com.amazonaws.services.s3.AmazonS3ClientBuilder;\n\n\npublic class Kafka2S3Route extends RouteBuilder {\n\t\n\tprivate static final Logger LOGGER = LoggerFactory.getLogger(Kafka2S3Route.class);\n\t\n\tprivate AmazonS3 s3Client;\n\t\n\t@PropertyInject(\"s3.custom.endpoint.enabled\")\n    private String s3_custom_endpoint_enabled;\n\n\t@PropertyInject(\"s3.custom.endpoint.url\")\n    private String s3_custom_endpoint_url;\n\t\n\t@PropertyInject(\"s3.accessKey\")\n    private String s3_accessKey;\n\t\n\t@PropertyInject(\"s3.secretKey\")\n    private String s3_secretKey;\n\t\n\t@PropertyInject(\"s3.message.aggregation.count\")\n    private String s3_message_aggregation_count;\n\t\n\t@PropertyInject(\"s3.region\")\n    private String s3_region;\n\n\t@Override\n\tpublic void configure() throws Exception {\n\n\t\tsetupAWSClient();\n\t\tstoreTemperatureInS3();\n\t\tstoreVibrationInS3();\n\n\t}\n\t\n\tprivate void setupAWSClient() {\n\t\t\n\t\t// key: wtFLMAxRcAUqJ2FCnCYW\n\t\t// secret-key: 6kit6yLBeiRkC51PuM8G8vYbwhjVBlNhT0RuVtJj\n\t\t\n\t\tif(Boolean.valueOf(s3_custom_endpoint_enabled)) {\n\t\t\t\n\t\t\tLOGGER.info(\"Custom S3 endpoint is enabled. Using: \"+s3_custom_endpoint_url);\n\t\t\t\n\t\t\tSystem.setProperty(SDKGlobalConfiguration.DISABLE_CERT_CHECKING_SYSTEM_PROPERTY, \"true\");\n\t\t\t\n\t\t\ts3Client = AmazonS3ClientBuilder.standard()\n                .withClientConfiguration(new ClientConfiguration().withProtocol(Protocol.HTTPS))\n                .withCredentials(new AWSStaticCredentialsProvider(new BasicAWSCredentials(s3_accessKey, s3_secretKey)))\n                .withEndpointConfiguration(new EndpointConfiguration(s3_custom_endpoint_url, \"\"))\n                .enablePathStyleAccess()\n                .build();\n\t\t} else {\n\t\t\t\n\t\t\tLOGGER.info(\"Using AWS S3 endpoint\");\n\t\t\t\n\t\t\ts3Client = AmazonS3ClientBuilder.standard()\n                .withClientConfiguration(new ClientConfiguration().withProtocol(Protocol.HTTPS))\n                .withCredentials(new AWSStaticCredentialsProvider(new BasicAWSCredentials(s3_accessKey, s3_secretKey)))\n                .withRegion(s3_region)\n                .enablePathStyleAccess()\n                .build();\n\t\t}\n\t\t\n\t\tbindToRegistry(\"client\", s3Client);\n\n\t}\n\n\tprivate void storeVibrationInS3() {\n\t\tfrom(\"kafka:{{kafka.broker.topic.vibration}}?brokers={{kafka.broker.uri}}\")\n\t\t\t.convertBodyTo(String.class)\n\t\t\t.aggregate(simple(\"true\"), new GroupedBodyAggregationStrategy()).completionSize(s3_message_aggregation_count)\n\t\t\t.process(new Processor() {\n\t\t\t\t@Override\n\t\t\t\tpublic void process(Exchange exchange) throws Exception {\n\t\t\t\t\tList<Exchange> data = exchange.getIn().getBody(List.class);\n\t\t\t\t\tStringBuffer sb = new StringBuffer();\n\t\t\t\t\tfor (Iterator iterator = data.iterator(); iterator.hasNext();) {\n\t\t\t\t\t\tString ex = (String) iterator.next();\n\t\t\t\t\t\tsb.append(ex+\"\\n\");\n\t\t\t\t\t}\n\t\t\t\t\texchange.getIn().setBody(new ByteArrayInputStream(sb.toString().getBytes()));\n\t\t\t\t}\n\t\t\t})\n\t\t\t// .to(\"file:/var/tmp/\");\n\t\t  .setHeader(S3Constants.KEY, simple(\"manuela-vibration-${date:now}.txt\"))\n\t\t  .to(\"aws-s3://{{s3.bucket.name}}?amazonS3Client=#client\")\n\t\t  .log(\"Uploaded Vibration dataset to S3\");\n\t\t\t \n\t}\n\n\tprivate void storeTemperatureInS3() {\n\t\tfrom(\"kafka:{{kafka.broker.topic.temperature}}?brokers={{kafka.broker.uri}}\")\n\t\t\t.convertBodyTo(String.class)\n\t\t\t.aggregate(simple(\"true\"), new GroupedBodyAggregationStrategy()).completionSize(s3_message_aggregation_count)\n\t\t\t.process(new Processor() {\n\t\t\t\t@Override\n\t\t\t\tpublic void process(Exchange exchange) throws Exception {\n\t\t\t\t\t\tList<Exchange> data = exchange.getIn().getBody(List.class);\n\t\t\t\t\t\tStringBuffer sb = new StringBuffer();\n\t\t\t\t\t\tfor (Iterator iterator = data.iterator(); iterator.hasNext();) {\n\t\t\t\t\t\t\tString ex = (String) iterator.next();\n\t\t\t\t\t\t\tsb.append(ex+\"\\n\");\n\t\t\t\t\t\t}\n\t\t\t\t\t\texchange.getIn().setBody(new ByteArrayInputStream(sb.toString().getBytes()));\t\t\t\t\t\t\n\t\t\t\t\t}\n\t\t\t})\n\t\t\t// .to(\"file:/var/tmp/\");\n    \t\t.setHeader(S3Constants.KEY, simple(\"manuela-temperature-${date:now}.txt\"))\n    \t\t.to(\"aws-s3://{{s3.bucket.name}}?amazonS3Client=#client\")\n    \t\t.log(\"Uploaded Temperature dataset to S3\");\n\t}\n\n\t@Override\n\tpublic OnCompletionDefinition onCompletion() {\n\t\treturn super.onCompletion();\n\t}\n}\n"
      name: Kafka2S3Route.java